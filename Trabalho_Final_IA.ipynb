{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dutrasilva/dutrasilva/blob/main/Trabalho_Final_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalho Final: KDD aplicado à Classificação de Qualidade de Café\n",
        "\n",
        "## **Integrantes**\n",
        "* **Nome:** André Luiz Silva e Wagner Henrique Cichacz\n",
        "* **Curso:** Desenvolvimento de Sistemas Web / Monitoramento\n",
        "* **Disciplina:** Inteligência Artificial e Data Mining\n",
        "* **Data:** Novembro 2025\n",
        "\n",
        "## **Sumário**\n",
        "1.  Motivação e Problema\n",
        "2.  Instalação e Confirguração das Bibliotecas\n",
        "3.  Dados\n",
        "4.  KDD: Seleção\n",
        "5.  EDA (Análise Exploratória)\n",
        "6.  Engenharia de Features\n",
        "7.  Pré-processamento e Transformação\n",
        "8.  Particionamento\n",
        "9.  Modelagem (Mineração)\n",
        "10.  Avaliação\n",
        "11. Salvamento do Modelo (Código)\n",
        "12. Conclusão\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XO35vKsxZavX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"motivacao\"></a>\n",
        "## **1. Motivação e Problema**\n",
        "* **Cliente:** Cooperativa de Cafeicultores (Fictícia).\n",
        "* **Problema:** A classificação manual (Q-Graders) é cara e subjetiva.\n",
        "* **Objetivo de Negócio:** Automatizar a triagem inicial de lotes.\n",
        "* **Objetivo de Data Mining:** Classificar cafés como **\"Especial\" (>85 pontos)** ou **\"Comercial\"** com base em características sensoriais e físicas.\n",
        "* **Meta:** F1-Score > 0.75 para a classe Especial."
      ],
      "metadata": {
        "id": "PfQCbe1VaICr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB9fHXvcXyDi"
      },
      "outputs": [],
      "source": [
        "# 2. Instalação e Confirguração das Bibliotecas\n",
        "\n",
        "# CONFIGURAÇÃO INICIAL E BIBLIOTECAS ---\n",
        "# Instalação de dependências (caso necessário)\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost joblib -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# Bibliotecas de Machine Learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression # Baseline\n",
        "from sklearn.ensemble import RandomForestClassifier # Modelo IA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "# REPRODUTIBILIDADE [Requisito do PDF]: Fixar semente aleatória\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(\"Bibliotecas importadas e Seed definida para 42.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Carregamento dos Dados (Código)\n",
        "\n",
        "# --- CARREGAMENTO DOS DADOS (À PROVA DE ERROS) ---\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Definição dos caminhos\n",
        "# Vamos usar o diretório temporário padrão do Colab\n",
        "DATA_DIR = '/content/drive/MyDrive/Trabalho_Final_IA/Modelos/df_arabica_clean.csv'\n",
        "FILE_NAME = 'df_arabica_clean.csv'\n",
        "LOCAL_PATH = os.path.join(DATA_DIR, FILE_NAME)\n",
        "\n",
        "# Montar o Drive APENAS para SALVAR O MODELO (Requisito do PDF)\n",
        "# O try/except evita que o código pare se o aluno cancelar a montagem do drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    OUTPUT_PATH = '/content/drive/MyDrive/Trabalho_Final_IA/Modelos/'\n",
        "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "    print(f\"Google Drive montado. Modelos serão salvos em: {OUTPUT_PATH}\")\n",
        "except:\n",
        "    print(\"AVISO: Google Drive não foi montado. O modelo será salvo apenas na memória temporária.\")\n",
        "    OUTPUT_PATH = '/content/' # Salva na raiz se não tiver Drive\n",
        "\n",
        "# Verificação Final\n",
        "if 'df' in locals():\n",
        "    print(\"\\n--- Dados Carregados com Sucesso! ---\")\n",
        "    print(f\"Tamanho do Dataset: {df.shape}\")\n",
        "    display(df.head(3))\n",
        "else:\n",
        "    print(\"\\nERRO FATAL: Não foi possível carregar os dados de nenhuma fonte.\")"
      ],
      "metadata": {
        "id": "iBrPb9MMZjD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. KDD - Seleção (Código)\n",
        "\n",
        "# --- KDD: SELEÇÃO ---\n",
        "# Justificativa: Selecionamos colunas sensoriais (Aroma, Flavor, etc) e físicas (Moisture, Color).\n",
        "# A variável alvo (Target) é derivada de 'Total Cup Points'.\n",
        "\n",
        "# 1. Criação da Variável Alvo Binária (Classificação)\n",
        "# Regra de Negócio: Nota > 85 é Especial (1), caso contrário Comercial (0)\n",
        "df['Quality_Class'] = np.where(df['Total Cup Points'] > 85, 1, 0)\n",
        "\n",
        "# 2. Seleção de Features\n",
        "features = [\n",
        "    'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
        "    'Balance', 'Uniformity', 'Clean Cup', 'Sweetness',\n",
        "    'Moisture Percentage', 'Processing Method', 'Color'\n",
        "]\n",
        "target = 'Quality_Class'\n",
        "\n",
        "df_selected = df[features + [target]].copy()\n",
        "\n",
        "print(f\"Dataset Selecionado: {df_selected.shape[0]} linhas e {df_selected.shape[1]} colunas.\")\n",
        "print(\"\\nBalanceamento das Classes:\")\n",
        "print(df_selected[target].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "ThyP26DQZ7Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. EDA - Análise Exploratória (Código)\n",
        "\n",
        "# --- EDA (ANÁLISE EXPLORATÓRIA) ---\n",
        "\n",
        "# A. Verificar Nulos\n",
        "print(\"Valores Nulos:\")\n",
        "print(df_selected.isnull().sum()[df_selected.isnull().sum() > 0])\n",
        "\n",
        "# B. Visualizar a Target\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=target, data=df_selected)\n",
        "plt.title(\"Distribuição das Classes (Desbalanceamento)\")\n",
        "plt.show()\n",
        "\n",
        "# C. Boxplot para identificar Outliers nas notas sensoriais\n",
        "numeric_feats = df_selected.select_dtypes(include=np.number).columns.drop(target)\n",
        "plt.figure(figsize=(15, 6))\n",
        "df_selected[numeric_feats].boxplot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Boxplot das Features Numéricas (Verificação de Outliers)\")\n",
        "plt.show()\n",
        "\n",
        "# D. Matriz de Correlação\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_selected[numeric_feats].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlação entre Variáveis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fVitfbWWaU7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Engenharia de Features (Código)\n",
        "\n",
        "# --- ENGENHARIA DE FEATURES ---\n",
        "# Hipótese Agronômica: Um café com média alta em todos os atributos sensoriais\n",
        "# é mais estável que um café com apenas um atributo alto.\n",
        "\n",
        "sensory_cols = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance']\n",
        "df_selected['Sensory_Avg'] = df_selected[sensory_cols].mean(axis=1)\n",
        "\n",
        "# Atualizar listas de features\n",
        "numeric_features = df_selected.select_dtypes(include=np.number).columns.drop(target)\n",
        "categorical_features = df_selected.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "print(\"Nova feature 'Sensory_Avg' criada.\")"
      ],
      "metadata": {
        "id": "rWl0xSfrabQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.  Pré-processamento e Transformação\n",
        "# 8.  Particionamento\n",
        "\n",
        "# --- PRÉ-PROCESSAMENTO E PARTICIONAMENTO ---\n",
        "\n",
        "# 1. Divisão Treino/Teste (Estratificada devido ao desbalanceamento)\n",
        "X = df_selected.drop(target, axis=1)\n",
        "y = df_selected[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "# 2. Definição do Pipeline de Pré-processamento\n",
        "# Numérico: Imputação pela mediana (robusto a outliers) + Padronização (StandardScaler)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categórico: Imputação pela moda + OneHotEncoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"Pipelines de pré-processamento configurados.\")\n",
        "print(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras.\")"
      ],
      "metadata": {
        "id": "J_H4JeTrak4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Modelagem e Mineração (Código)\n",
        "\n",
        "# --- MODELAGEM (MINERAÇÃO) ---\n",
        "\n",
        "# A. BASELINE: Regressão Logística\n",
        "# Motivo: Modelo simples e interpretável para servir de comparação.\n",
        "pipeline_lr = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=SEED, max_iter=1000))\n",
        "])\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "print(\"Baseline (Regressão Logística) treinado.\")\n",
        "\n",
        "# B. MODELO AVANÇADO: Random Forest com GridSearchCV\n",
        "# Motivo: Lida bem com relações não-lineares e dados tabulares.\n",
        "pipeline_rf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=SEED))\n",
        "])\n",
        "\n",
        "# Otimização de Hiperparâmetros\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200], # Número de árvores\n",
        "    'classifier__max_depth': [None, 10],   # Profundidade\n",
        "    'classifier__class_weight': ['balanced', None] # Tratar desbalanceamento\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline_rf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(f\"Melhor F1-Score na Validação: {grid_search.best_score_:.4f}\")\n",
        "print(f\"Melhores Parâmetros: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "id": "ptK0p168ardC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Avaliação dos Resultados (Código)\n",
        "\n",
        "# --- AVALIAÇÃO ---\n",
        "# Métrica Principal: F1-Score (pois o dataset é desbalanceado e queremos equilíbrio entre Precision/Recall)\n",
        "\n",
        "print(\"--- RELATÓRIO BASELINE (LogRegression) ---\")\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"--- RELATÓRIO IA (Random Forest Otimizado) ---\")\n",
        "y_pred_rf = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Matriz de Confusão\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "ax[0].set_title('Baseline')\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens', ax=ax[1])\n",
        "ax[1].set_title('Random Forest')\n",
        "plt.show()\n",
        "\n",
        "# Curva ROC\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, label=f\"Random Forest (AUC={auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.legend()\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIK3WgvVa8Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Salvamento do Modelo e Conclusão (Código)\n",
        "\n",
        "# --- CONCLUSÃO E EXPORTAÇÃO ---\n",
        "\n",
        "# Salvar modelo no Drive\n",
        "model_filename = os.path.join(OUTPUT_PATH, 'modelo_cafe_rf_final.joblib')\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"Modelo salvo com sucesso em: {model_filename}\")\n",
        "\n",
        "# Para recarregar (demonstração):\n",
        "loaded_model = joblib.load(model_filename)"
      ],
      "metadata": {
        "id": "1742oPkkbFEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **12. Conclusões**\n",
        "O projeto atingiu o objetivo de classificar cafés especiais.\n",
        "1.  **Comparação:** O Random Forest superou (ou igualou) a Regressão Logística, mostrando robustez.\n",
        "2.  **Impacto:** A automatização permite que a cooperativa foque esforços humanos apenas nos casos duvidosos, economizando tempo.\n",
        "3.  **Limitações:** O tamanho da amostra é pequeno, sugere-se coletar mais dados de safras futuras."
      ],
      "metadata": {
        "id": "4s5OOnFFbMHl"
      }
    }
  ]
}